{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-06T21:39:38.034615Z","iopub.status.busy":"2024-04-06T21:39:38.034304Z","iopub.status.idle":"2024-04-06T21:39:45.161836Z","shell.execute_reply":"2024-04-06T21:39:45.161059Z","shell.execute_reply.started":"2024-04-06T21:39:38.034591Z"},"id":"rmyCr3OgROUT","trusted":true},"outputs":[],"source":["from torchvision.datasets import Flowers102\n","import multiprocessing\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from torchvision import transforms\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import os\n","import pandas as pd\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-06T21:39:56.357556Z","iopub.status.busy":"2024-04-06T21:39:56.356578Z","iopub.status.idle":"2024-04-06T21:39:56.362787Z","shell.execute_reply":"2024-04-06T21:39:56.361675Z","shell.execute_reply.started":"2024-04-06T21:39:56.357526Z"},"id":"76Y_VBtfROUV","outputId":"8c892f4f-4292-45cf-961e-3529c23d2322","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of CPU cores available: 4\n"]}],"source":["num_workers = multiprocessing.cpu_count()\n","print(\"Number of CPU cores available:\", num_workers)\n","batch_size = 4"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-06T21:39:58.722733Z","iopub.status.busy":"2024-04-06T21:39:58.722366Z","iopub.status.idle":"2024-04-06T21:40:24.292118Z","shell.execute_reply":"2024-04-06T21:40:24.291297Z","shell.execute_reply.started":"2024-04-06T21:39:58.722705Z"},"id":"U-UvzU-3ROUX","outputId":"f8d03bd5-ef44-496e-a27b-d6c4afd683a3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to flowers-102/102flowers.tgz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 344862509/344862509 [00:12<00:00, 27321536.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting flowers-102/102flowers.tgz to flowers-102\n","Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to flowers-102/imagelabels.mat\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 502/502 [00:00<00:00, 407418.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to flowers-102/setid.mat\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14989/14989 [00:00<00:00, 9206094.99it/s]\n"]}],"source":["class DataProvider(Dataset):\n","\n","    def __init__(self, sample_dataset, label_dataset):\n","        self.sample_dataset = sample_dataset\n","        self.label_dataset = label_dataset\n","\n","    def __len__(self):\n","        return len(self.sample_dataset)\n","\n","    def __getitem__(self, idx):\n","        sample = self.sample_dataset[idx][0]\n","        label = self.label_dataset[idx][0]\n","        return (sample, label)\n","\n","\n","transform_Grayscale = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor()\n","])\n","\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])\n","\n","# Load sample datasets rgb image\n","train_set_sample = Flowers102(root='.', split='train', download=True, transform=transform)\n","test_set_sample = Flowers102(root='.', split='test', download=True, transform=transform)\n","validation_set_sample = Flowers102(root='.', split='val', download=True, transform=transform)\n","\n","# Load label datasets - grayscale images as labels)\n","train_set_label = Flowers102(root='.', split='train', download=True, transform=transform_Grayscale)\n","test_set_label = Flowers102(root='.', split='test', download=True, transform=transform_Grayscale)\n","validation_set_label = Flowers102(root='.', split='val', download=True, transform=transform_Grayscale)\n","\n","train_set = DataProvider(train_set_sample, train_set_label)\n","test_set = DataProvider(test_set_sample, test_set_label)\n","validation_set = DataProvider(validation_set_sample, validation_set_label)\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-06T21:41:01.565771Z","iopub.status.busy":"2024-04-06T21:41:01.565416Z","iopub.status.idle":"2024-04-06T21:41:01.570852Z","shell.execute_reply":"2024-04-06T21:41:01.569919Z","shell.execute_reply.started":"2024-04-06T21:41:01.565743Z"},"id":"Hj0sx3OjROUZ","outputId":"ce0b9f78-0418-4f7e-b861-a584f21d1d2e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device:', device)"]},{"cell_type":"markdown","metadata":{"id":"RriO1C6qROUa"},"source":["# Generator - UNET"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T21:41:03.670995Z","iopub.status.busy":"2024-04-06T21:41:03.670526Z","iopub.status.idle":"2024-04-06T21:41:03.686811Z","shell.execute_reply":"2024-04-06T21:41:03.685896Z","shell.execute_reply.started":"2024-04-06T21:41:03.670966Z"},"id":"Z9eFuvj_ROUd","trusted":true},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(EncoderBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DecoderBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","class UNetGenerator(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNetGenerator, self).__init__()\n","\n","        # Define encoder blocks\n","        self.encoder1 = EncoderBlock(in_channels, 64)\n","        self.encoder2 = EncoderBlock(64, 128)\n","        self.encoder3 = EncoderBlock(128, 256)\n","        self.encoder4 = EncoderBlock(256, 512)\n","        self.encoder5 = EncoderBlock(512, 1024)\n","\n","        # Define decoder blocks=\n","        self.decoder1 = DecoderBlock(1024, 512)\n","        self.decoder2 = DecoderBlock(512 + 512, 256)\n","        self.decoder3 = DecoderBlock(256 + 256, 128)\n","        self.decoder4 = DecoderBlock(128 + 128, 64)\n","        self.decoder5 = DecoderBlock(64 + 64, out_channels)\n","\n","    def forward(self, x):\n","        # Encoding\n","        x1 = self.encoder1(x)\n","        x2 = self.encoder2(x1)\n","        x3 = self.encoder3(x2)\n","        x4 = self.encoder4(x3)\n","        x5 = self.encoder5(x4)\n","\n","        # Decoding with skip connections\n","        y = self.decoder1(x5)\n","        y = torch.cat([y, x4], dim=1)\n","        y = self.decoder2(y)\n","        y = torch.cat([y, x3], dim=1)\n","        y = self.decoder3(y)\n","        y = torch.cat([y, x2], dim=1)\n","        y = self.decoder4(y)\n","        y = torch.cat([y, x1], dim=1)\n","        y = self.decoder5(y)\n","\n","        return y\n"]},{"cell_type":"markdown","metadata":{"id":"wibohoHIROUe"},"source":["# Critic - CNN"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T21:41:06.463586Z","iopub.status.busy":"2024-04-06T21:41:06.463221Z","iopub.status.idle":"2024-04-06T21:41:06.474791Z","shell.execute_reply":"2024-04-06T21:41:06.473886Z","shell.execute_reply.started":"2024-04-06T21:41:06.463558Z"},"id":"q9Zx8-q7ROUf","trusted":true},"outputs":[],"source":["class VGG_block(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(VGG_block, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.InstanceNorm2d(out_channels, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.InstanceNorm2d(out_channels, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.MaxPool2d(2)\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","    \n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        \n","        # Define blocks\n","        self.layer1 = VGG_block(3, 64)\n","        self.layer2 = VGG_block(64, 128)\n","        self.layer3 = VGG_block(128, 256)\n","        self.layer4 = VGG_block(256, 512)\n","        self.layer5 = VGG_block(512, 1024)\n","        self.layer6 = VGG_block(1024, 1024)\n","        \n","        # Final convolutional layer\n","        self.final_conv = nn.Sequential(\n","            nn.Conv2d(1024, 1, kernel_size=3, stride=1, padding=1, bias=False)\n","        )\n","\n","    def forward(self, img):\n","        x1 = self.layer1(img)\n","        x2 = self.layer2(x1)\n","        x3 = self.layer3(x2)\n","        x4 = self.layer4(x3)\n","        x5 = self.layer5(x4)\n","        x6 = self.layer6(x5)\n","        output = self.final_conv(x6)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvdMK8GMROUh","trusted":true},"outputs":[],"source":["# Initialize the generator and discriminator\n","generator = UNetGenerator(in_channels=1, out_channels=3)  \n","discriminator = Discriminator()\n","\n","optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.0, 0.9))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.0, 0.9))\n","\n","criterion = nn.MSELoss()\n","\n","generator.to(device)\n","discriminator.to(device)"]},{"cell_type":"markdown","metadata":{"id":"5p3umAwPROUi"},"source":["# Pretraining"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T21:41:14.995712Z","iopub.status.busy":"2024-04-06T21:41:14.995049Z","iopub.status.idle":"2024-04-06T22:49:14.943081Z","shell.execute_reply":"2024-04-06T22:49:14.941947Z","shell.execute_reply.started":"2024-04-06T21:41:14.995680Z"},"id":"vjUgB4WrROUi","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch number: 0\n","epoch number: 20\n","epoch number: 40\n","epoch number: 60\n","epoch number: 80\n","epoch number: 0\n","epoch number: 20\n","epoch number: 40\n","epoch number: 60\n","epoch number: 80\n"]}],"source":["def pretrain_generator(generator, criterion, optimizer, train_loader):\n","    generator.train()  # Set the generator to training mode\n","    for epoch in range(100):\n","        for real_image, grey_image in train_loader:\n","            grey_image = grey_image.to(device)\n","            real_image = real_image.to(device)\n","\n","            # Generate fake images\n","            fake_image = generator(grey_image)\n","\n","            # Compute generator loss\n","            generator_loss = criterion(fake_image, real_image)\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            generator_loss.backward()\n","            optimizer.step()\n","        if(epoch % 20 == 0):\n","            print(f'epoch number: {epoch}')\n","\n","def pretrain_discriminator(discriminator, criterion, optimizer, train_loader):\n","    discriminator.train()  # Set the discriminator to training mode\n","    for epoch in range(100):\n","        for real_image, grey_image in train_loader:\n","            grey_image = grey_image.to(device)\n","            real_image = real_image.to(device)\n","\n","            # Generate fake images\n","            fake_image = generator(grey_image).detach()\n","\n","            # Compute discriminator loss\n","            real_output = discriminator(real_image)\n","            fake_output = discriminator(fake_image)\n","            discriminator_loss_real = criterion(real_output, torch.ones_like(real_output))\n","            discriminator_loss_fake = criterion(fake_output, torch.zeros_like(fake_output))\n","            discriminator_loss = (discriminator_loss_real + discriminator_loss_fake) / 2\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            discriminator_loss.backward()\n","            optimizer.step()\n","        if(epoch % 20 == 0):\n","            print(f'epoch number: {epoch}')\n","\n","\n","# Pretraining the generator\n","pretrain_generator(generator, criterion, optimizer_G, train_loader)\n","\n","# Pretraining the discriminator\n","pretrain_discriminator(discriminator, criterion, optimizer_D, train_loader)\n","\n","torch.save(generator.state_dict(), f\"MSE_generator_epoch.pt\")\n","torch.save(discriminator.state_dict(), f\"MSE_discriminator_epoch.pt\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T22:49:19.193574Z","iopub.status.busy":"2024-04-06T22:49:19.193236Z","iopub.status.idle":"2024-04-06T22:49:19.209104Z","shell.execute_reply":"2024-04-06T22:49:19.208129Z","shell.execute_reply.started":"2024-04-06T22:49:19.193543Z"},"id":"KfJiv7yhROUj","trusted":true},"outputs":[],"source":["def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n","    # Generate random interpolation factors between real and fake samples\n","    alpha = torch.rand(real_samples.size(0), 1, 1, 1).to(device)\n","\n","    # Perform linear interpolation between real and fake samples\n","    interpolates = alpha * real_samples + (1 - alpha) * fake_samples\n","\n","    # Allow gradients for interpolation points\n","    interpolates.requires_grad_(True)\n","\n","    # Pass interpolation points through the discriminator\n","    d_interpolates = discriminator(interpolates)\n","\n","    # Create gradient tensors for each interpolation point\n","    grad_outputs = torch.ones_like(d_interpolates, requires_grad=False).to(device)\n","\n","    # Compute gradients of discriminator outputs w.r.t. interpolation points\n","    gradients = torch.autograd.grad(outputs=d_interpolates, inputs=interpolates, grad_outputs=grad_outputs, create_graph=True, retain_graph=True)[0]\n","\n","    # Flatten gradients to compute norm per sample\n","    gradients = gradients.view(gradients.size(0), -1)\n","\n","    # Compute gradient penalty as per WGAN-GP formula\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","    return gradient_penalty\n","\n","\n","def psnr(image_true, image_pred):\n","    mse = F.mse_loss(image_pred, image_true)\n","    max_pixel = 1.0\n","    return 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","\n","\n","def validate(generator, criterion, validation_loader):\n","    generator.eval()  # Set the generator to evaluation mode\n","    total_loss = 0\n","    total_psnr = 0\n","    total_mae = 0\n","\n","    with torch.no_grad():\n","        for real_image, grey_image in validation_loader:\n","            grey_image = grey_image.to(device)\n","            real_image = real_image.to(device)\n","            # Generate fake images\n","            fake_image = generator(grey_image)\n","\n","            # Compute MSE loss\n","            loss = criterion(fake_image, real_image)\n","            # Accumulate total loss\n","            total_loss += loss.item()\n","\n","            # Compute PSNR\n","            psnr_value = psnr(real_image, fake_image)\n","            total_psnr += psnr_value.item()\n","\n","\n","            # Compute MAE\n","            mae_value = F.l1_loss(fake_image, real_image)\n","            total_mae += mae_value.item()\n","\n","    # Calculate average validation loss and other metrics\n","    avg_loss = total_loss / len(validation_loader)\n","    avg_psnr = total_psnr / len(validation_loader)\n","    # avg_ssim = total_ssim / len(validation_loader)\n","    avg_mae = total_mae / len(validation_loader)\n","\n","    # return avg_loss, avg_psnr, avg_ssim, avg_mae\n","    return avg_loss, avg_psnr, avg_mae\n","\n","\n","def loadModel():\n","    generator.load_state_dict(torch.load('/kaggle/working/MSE_generator_epoch.pt'))\n","    discriminator.load_state_dict(torch.load('/kaggle/working/MSE_discriminator_epoch.pt'))\n","    print(\"Models found in both paths.\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T22:49:19.225101Z","iopub.status.busy":"2024-04-06T22:49:19.224764Z","iopub.status.idle":"2024-04-06T22:49:19.233596Z","shell.execute_reply":"2024-04-06T22:49:19.232644Z","shell.execute_reply.started":"2024-04-06T22:49:19.225071Z"},"id":"TBPSXPPbROUm","trusted":true},"outputs":[],"source":["# Hyperparameters\n","mini_batch = 64\n","batch_epoch = 16\n","gradient_penalty_lambda = 10\n","lambda_mse = 0.95\n","lambda_wgan = 0.05\n","n_critic = 2\n","\n","# Training loop\n","num_epochs = 10\n","save_every_epoch = 2\n","\n","# Lists to store losses\n","train_losses_discriminator = []\n","train_losses_generator = []\n","mse_losses = []\n","validation_losses = []\n","psnr_values = []\n","mae_values = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-06T22:49:19.235167Z","iopub.status.busy":"2024-04-06T22:49:19.234900Z"},"id":"XX7atmu8ROUm","outputId":"4959e699-f45b-4db8-8830-88ad944db1e1","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Models found in both paths.\n","Epoch [0/10], Batch [0/255], Generator WGAN Loss: -0.0110, Generator MSE Loss: 0.0013, Discriminator Loss: 6.8930\n","Epoch [0/10], Batch [16/255], Generator WGAN Loss: -0.0873, Generator MSE Loss: 0.0032, Discriminator Loss: 0.8992\n","Epoch [0/10], Batch [32/255], Generator WGAN Loss: -0.0577, Generator MSE Loss: 0.0021, Discriminator Loss: 2.7579\n","Epoch [0/10], Batch [48/255], Generator WGAN Loss: -0.0684, Generator MSE Loss: 0.0023, Discriminator Loss: 1.6442\n","Epoch [0/10], Batch [64/255], Generator WGAN Loss: -0.0501, Generator MSE Loss: 0.0031, Discriminator Loss: 1.9743\n","Epoch [0/10], Batch [80/255], Generator WGAN Loss: -0.0489, Generator MSE Loss: 0.0019, Discriminator Loss: 0.1718\n","Epoch [0/10], Batch [96/255], Generator WGAN Loss: -0.0476, Generator MSE Loss: 0.0027, Discriminator Loss: 0.3673\n","Epoch [0/10], Batch [112/255], Generator WGAN Loss: -0.0487, Generator MSE Loss: 0.0017, Discriminator Loss: 0.3567\n","Epoch [0/10], Batch [128/255], Generator WGAN Loss: -0.0746, Generator MSE Loss: 0.0024, Discriminator Loss: 0.3682\n","Epoch [0/10], Batch [144/255], Generator WGAN Loss: -0.0399, Generator MSE Loss: 0.0027, Discriminator Loss: 0.1117\n","Epoch [0/10], Batch [160/255], Generator WGAN Loss: -0.0377, Generator MSE Loss: 0.0028, Discriminator Loss: 0.4445\n","Epoch [0/10], Batch [176/255], Generator WGAN Loss: -0.0974, Generator MSE Loss: 0.0057, Discriminator Loss: 0.1040\n","Epoch [0/10], Batch [192/255], Generator WGAN Loss: -0.0929, Generator MSE Loss: 0.0038, Discriminator Loss: 0.2510\n","Epoch [0/10], Batch [208/255], Generator WGAN Loss: -0.0203, Generator MSE Loss: 0.0082, Discriminator Loss: 0.0351\n","Epoch [0/10], Batch [224/255], Generator WGAN Loss: -0.0285, Generator MSE Loss: 0.0019, Discriminator Loss: 0.1028\n","Epoch [0/10], Batch [240/255], Generator WGAN Loss: 0.0050, Generator MSE Loss: 0.0016, Discriminator Loss: 0.2756\n","Epoch [0/10], Validation Loss: 0.0176\n","Epoch [1/10], Batch [0/255], Generator WGAN Loss: 0.0115, Generator MSE Loss: 0.0030, Discriminator Loss: 0.0103\n","Epoch [1/10], Batch [16/255], Generator WGAN Loss: 0.0223, Generator MSE Loss: 0.0047, Discriminator Loss: 0.5471\n","Epoch [1/10], Batch [32/255], Generator WGAN Loss: 0.0026, Generator MSE Loss: 0.0017, Discriminator Loss: 0.3286\n","Epoch [1/10], Batch [48/255], Generator WGAN Loss: -0.0079, Generator MSE Loss: 0.0018, Discriminator Loss: 0.1639\n","Epoch [1/10], Batch [64/255], Generator WGAN Loss: -0.0213, Generator MSE Loss: 0.0017, Discriminator Loss: 0.7389\n","Epoch [1/10], Batch [80/255], Generator WGAN Loss: -0.0230, Generator MSE Loss: 0.0017, Discriminator Loss: 0.3680\n","Epoch [1/10], Batch [96/255], Generator WGAN Loss: -0.0151, Generator MSE Loss: 0.0025, Discriminator Loss: 0.1044\n","Epoch [1/10], Batch [112/255], Generator WGAN Loss: -0.0174, Generator MSE Loss: 0.0031, Discriminator Loss: 0.2907\n","Epoch [1/10], Batch [128/255], Generator WGAN Loss: -0.0290, Generator MSE Loss: 0.0021, Discriminator Loss: 0.2370\n","Epoch [1/10], Batch [144/255], Generator WGAN Loss: -0.0309, Generator MSE Loss: 0.0048, Discriminator Loss: 0.3429\n","Epoch [1/10], Batch [160/255], Generator WGAN Loss: -0.0443, Generator MSE Loss: 0.0027, Discriminator Loss: 0.0950\n","Epoch [1/10], Batch [176/255], Generator WGAN Loss: -0.0358, Generator MSE Loss: 0.0017, Discriminator Loss: 0.4351\n","Epoch [1/10], Batch [192/255], Generator WGAN Loss: -0.0162, Generator MSE Loss: 0.0040, Discriminator Loss: 0.4624\n","Epoch [1/10], Batch [208/255], Generator WGAN Loss: -0.0134, Generator MSE Loss: 0.0025, Discriminator Loss: 1.2512\n","Epoch [1/10], Batch [224/255], Generator WGAN Loss: -0.0031, Generator MSE Loss: 0.0027, Discriminator Loss: 0.1949\n","Epoch [1/10], Batch [240/255], Generator WGAN Loss: 0.0103, Generator MSE Loss: 0.0019, Discriminator Loss: 0.1483\n","Epoch [1/10], Validation Loss: 0.0175\n","Epoch [2/10], Batch [0/255], Generator WGAN Loss: -0.0070, Generator MSE Loss: 0.0023, Discriminator Loss: 0.2555\n","Epoch [2/10], Batch [16/255], Generator WGAN Loss: -0.0055, Generator MSE Loss: 0.0024, Discriminator Loss: 0.5085\n","Epoch [2/10], Batch [32/255], Generator WGAN Loss: 0.0065, Generator MSE Loss: 0.0023, Discriminator Loss: 0.1469\n","Epoch [2/10], Batch [48/255], Generator WGAN Loss: -0.0060, Generator MSE Loss: 0.0022, Discriminator Loss: 0.1919\n","Epoch [2/10], Batch [64/255], Generator WGAN Loss: -0.0093, Generator MSE Loss: 0.0015, Discriminator Loss: 0.2524\n","Epoch [2/10], Batch [80/255], Generator WGAN Loss: -0.0135, Generator MSE Loss: 0.0028, Discriminator Loss: 0.1468\n","Epoch [2/10], Batch [96/255], Generator WGAN Loss: -0.0067, Generator MSE Loss: 0.0019, Discriminator Loss: 0.3783\n","Epoch [2/10], Batch [112/255], Generator WGAN Loss: -0.0141, Generator MSE Loss: 0.0024, Discriminator Loss: 0.1871\n","Epoch [2/10], Batch [128/255], Generator WGAN Loss: -0.0418, Generator MSE Loss: 0.0022, Discriminator Loss: 0.3401\n","Epoch [2/10], Batch [144/255], Generator WGAN Loss: -0.0571, Generator MSE Loss: 0.0020, Discriminator Loss: 0.1512\n","Epoch [2/10], Batch [160/255], Generator WGAN Loss: -0.0382, Generator MSE Loss: 0.0026, Discriminator Loss: 0.0842\n","Epoch [2/10], Batch [176/255], Generator WGAN Loss: -0.0297, Generator MSE Loss: 0.0026, Discriminator Loss: 0.5191\n","Epoch [2/10], Batch [192/255], Generator WGAN Loss: -0.0209, Generator MSE Loss: 0.0021, Discriminator Loss: 0.1835\n","Epoch [2/10], Batch [208/255], Generator WGAN Loss: -0.0297, Generator MSE Loss: 0.0029, Discriminator Loss: 0.1707\n","Epoch [2/10], Batch [224/255], Generator WGAN Loss: -0.0333, Generator MSE Loss: 0.0019, Discriminator Loss: 0.0802\n","Epoch [2/10], Batch [240/255], Generator WGAN Loss: -0.0221, Generator MSE Loss: 0.0024, Discriminator Loss: 1.0824\n","Epoch [2/10], Validation Loss: 0.0173\n","Epoch [3/10], Batch [0/255], Generator WGAN Loss: -0.0238, Generator MSE Loss: 0.0025, Discriminator Loss: 0.0487\n","Epoch [3/10], Batch [16/255], Generator WGAN Loss: -0.0261, Generator MSE Loss: 0.0049, Discriminator Loss: 0.4429\n","Epoch [3/10], Batch [32/255], Generator WGAN Loss: -0.0362, Generator MSE Loss: 0.0015, Discriminator Loss: 0.1629\n","Epoch [3/10], Batch [48/255], Generator WGAN Loss: -0.0388, Generator MSE Loss: 0.0014, Discriminator Loss: 0.0407\n","Epoch [3/10], Batch [64/255], Generator WGAN Loss: -0.0409, Generator MSE Loss: 0.0025, Discriminator Loss: 0.0535\n","Epoch [3/10], Batch [80/255], Generator WGAN Loss: -0.0494, Generator MSE Loss: 0.0021, Discriminator Loss: 0.7261\n","Epoch [3/10], Batch [96/255], Generator WGAN Loss: -0.0671, Generator MSE Loss: 0.0029, Discriminator Loss: 0.2441\n","Epoch [3/10], Batch [112/255], Generator WGAN Loss: -0.0620, Generator MSE Loss: 0.0015, Discriminator Loss: 0.0790\n","Epoch [3/10], Batch [128/255], Generator WGAN Loss: -0.0839, Generator MSE Loss: 0.0018, Discriminator Loss: 0.0853\n","Epoch [3/10], Batch [144/255], Generator WGAN Loss: -0.0741, Generator MSE Loss: 0.0029, Discriminator Loss: 0.2226\n","Epoch [3/10], Batch [160/255], Generator WGAN Loss: -0.0869, Generator MSE Loss: 0.0022, Discriminator Loss: 0.6076\n","Epoch [3/10], Batch [176/255], Generator WGAN Loss: -0.0907, Generator MSE Loss: 0.0024, Discriminator Loss: 0.1639\n","Epoch [3/10], Batch [192/255], Generator WGAN Loss: -0.0761, Generator MSE Loss: 0.0031, Discriminator Loss: 0.0731\n","Epoch [3/10], Batch [208/255], Generator WGAN Loss: -0.0913, Generator MSE Loss: 0.0035, Discriminator Loss: 0.0327\n","Epoch [3/10], Batch [224/255], Generator WGAN Loss: -0.0881, Generator MSE Loss: 0.0031, Discriminator Loss: 0.2998\n","Epoch [3/10], Batch [240/255], Generator WGAN Loss: -0.0760, Generator MSE Loss: 0.0020, Discriminator Loss: 0.2818\n","Epoch [3/10], Validation Loss: 0.0172\n","Epoch [4/10], Batch [0/255], Generator WGAN Loss: -0.0819, Generator MSE Loss: 0.0028, Discriminator Loss: 0.4233\n","Epoch [4/10], Batch [16/255], Generator WGAN Loss: -0.0865, Generator MSE Loss: 0.0020, Discriminator Loss: 0.0150\n","Epoch [4/10], Batch [32/255], Generator WGAN Loss: -0.0911, Generator MSE Loss: 0.0028, Discriminator Loss: 0.2942\n","Epoch [4/10], Batch [48/255], Generator WGAN Loss: -0.0877, Generator MSE Loss: 0.0020, Discriminator Loss: 0.0214\n","Epoch [4/10], Batch [64/255], Generator WGAN Loss: -0.0869, Generator MSE Loss: 0.0020, Discriminator Loss: 0.0619\n","Epoch [4/10], Batch [80/255], Generator WGAN Loss: -0.0820, Generator MSE Loss: 0.0026, Discriminator Loss: 0.0968\n","Epoch [4/10], Batch [96/255], Generator WGAN Loss: -0.0929, Generator MSE Loss: 0.0022, Discriminator Loss: 0.0765\n","Epoch [4/10], Batch [112/255], Generator WGAN Loss: -0.1057, Generator MSE Loss: 0.0020, Discriminator Loss: 0.0425\n","Epoch [4/10], Batch [128/255], Generator WGAN Loss: -0.1074, Generator MSE Loss: 0.0018, Discriminator Loss: 0.0843\n","Epoch [4/10], Batch [144/255], Generator WGAN Loss: -0.0898, Generator MSE Loss: 0.0021, Discriminator Loss: 0.9159\n","Epoch [4/10], Batch [160/255], Generator WGAN Loss: -0.0695, Generator MSE Loss: 0.0018, Discriminator Loss: 0.0229\n","Epoch [4/10], Batch [176/255], Generator WGAN Loss: -0.0438, Generator MSE Loss: 0.0029, Discriminator Loss: 2.2391\n","Epoch [4/10], Batch [192/255], Generator WGAN Loss: -0.0428, Generator MSE Loss: 0.0021, Discriminator Loss: 0.6533\n","Epoch [4/10], Batch [208/255], Generator WGAN Loss: -0.0195, Generator MSE Loss: 0.0023, Discriminator Loss: 0.3792\n","Epoch [4/10], Batch [224/255], Generator WGAN Loss: -0.0250, Generator MSE Loss: 0.0041, Discriminator Loss: 0.1015\n","Epoch [4/10], Batch [240/255], Generator WGAN Loss: -0.0300, Generator MSE Loss: 0.0024, Discriminator Loss: 2.0719\n","Epoch [4/10], Validation Loss: 0.0176\n","Epoch [5/10], Batch [0/255], Generator WGAN Loss: -0.0212, Generator MSE Loss: 0.0017, Discriminator Loss: 0.6344\n","Epoch [5/10], Batch [16/255], Generator WGAN Loss: -0.0146, Generator MSE Loss: 0.0016, Discriminator Loss: 0.3103\n","Epoch [5/10], Batch [32/255], Generator WGAN Loss: -0.0202, Generator MSE Loss: 0.0051, Discriminator Loss: 0.3477\n","Epoch [5/10], Batch [48/255], Generator WGAN Loss: -0.0157, Generator MSE Loss: 0.0020, Discriminator Loss: 0.0614\n","Epoch [5/10], Batch [64/255], Generator WGAN Loss: -0.0216, Generator MSE Loss: 0.0025, Discriminator Loss: 0.6584\n","Epoch [5/10], Batch [80/255], Generator WGAN Loss: -0.0200, Generator MSE Loss: 0.0028, Discriminator Loss: 0.3205\n","Epoch [5/10], Batch [96/255], Generator WGAN Loss: -0.0148, Generator MSE Loss: 0.0025, Discriminator Loss: 0.1149\n","Epoch [5/10], Batch [112/255], Generator WGAN Loss: -0.0117, Generator MSE Loss: 0.0040, Discriminator Loss: 0.5473\n","Epoch [5/10], Batch [128/255], Generator WGAN Loss: -0.0154, Generator MSE Loss: 0.0030, Discriminator Loss: 0.0198\n","Epoch [5/10], Batch [144/255], Generator WGAN Loss: -0.0215, Generator MSE Loss: 0.0023, Discriminator Loss: 0.0652\n","Epoch [5/10], Batch [160/255], Generator WGAN Loss: -0.0228, Generator MSE Loss: 0.0021, Discriminator Loss: 0.1166\n","Epoch [5/10], Batch [176/255], Generator WGAN Loss: -0.0227, Generator MSE Loss: 0.0021, Discriminator Loss: 0.0536\n","Epoch [5/10], Batch [192/255], Generator WGAN Loss: -0.0290, Generator MSE Loss: 0.0018, Discriminator Loss: 0.8752\n","Epoch [5/10], Batch [208/255], Generator WGAN Loss: -0.0233, Generator MSE Loss: 0.0022, Discriminator Loss: 0.7540\n","Epoch [5/10], Batch [224/255], Generator WGAN Loss: -0.0253, Generator MSE Loss: 0.0026, Discriminator Loss: 0.1090\n","Epoch [5/10], Batch [240/255], Generator WGAN Loss: -0.0239, Generator MSE Loss: 0.0023, Discriminator Loss: 0.1594\n","Epoch [5/10], Validation Loss: 0.0176\n","Epoch [6/10], Batch [0/255], Generator WGAN Loss: -0.0223, Generator MSE Loss: 0.0020, Discriminator Loss: 1.0621\n","Epoch [6/10], Batch [16/255], Generator WGAN Loss: -0.0247, Generator MSE Loss: 0.0018, Discriminator Loss: 0.0628\n","Epoch [6/10], Batch [32/255], Generator WGAN Loss: -0.0357, Generator MSE Loss: 0.0023, Discriminator Loss: 0.2258\n","Epoch [6/10], Batch [48/255], Generator WGAN Loss: -0.0283, Generator MSE Loss: 0.0030, Discriminator Loss: 0.6811\n","Epoch [6/10], Batch [64/255], Generator WGAN Loss: -0.0323, Generator MSE Loss: 0.0013, Discriminator Loss: 0.0689\n","Epoch [6/10], Batch [80/255], Generator WGAN Loss: -0.0101, Generator MSE Loss: 0.0029, Discriminator Loss: 0.6695\n","Epoch [6/10], Batch [96/255], Generator WGAN Loss: -0.0339, Generator MSE Loss: 0.0021, Discriminator Loss: 0.1126\n","Epoch [6/10], Batch [112/255], Generator WGAN Loss: -0.0328, Generator MSE Loss: 0.0025, Discriminator Loss: 0.3885\n","Epoch [6/10], Batch [128/255], Generator WGAN Loss: -0.0265, Generator MSE Loss: 0.0031, Discriminator Loss: 0.1840\n","Epoch [6/10], Batch [144/255], Generator WGAN Loss: -0.0290, Generator MSE Loss: 0.0025, Discriminator Loss: 0.5955\n","Epoch [6/10], Batch [160/255], Generator WGAN Loss: -0.0314, Generator MSE Loss: 0.0017, Discriminator Loss: 0.0985\n","Epoch [6/10], Batch [176/255], Generator WGAN Loss: -0.0284, Generator MSE Loss: 0.0037, Discriminator Loss: 0.1636\n","Epoch [6/10], Batch [192/255], Generator WGAN Loss: -0.0255, Generator MSE Loss: 0.0028, Discriminator Loss: 0.4373\n","Epoch [6/10], Batch [208/255], Generator WGAN Loss: -0.1333, Generator MSE Loss: 0.0023, Discriminator Loss: 1.1750\n","Epoch [6/10], Batch [224/255], Generator WGAN Loss: -0.0605, Generator MSE Loss: 0.0042, Discriminator Loss: 1.6750\n","Epoch [6/10], Batch [240/255], Generator WGAN Loss: -0.0279, Generator MSE Loss: 0.0030, Discriminator Loss: 2.7698\n","Epoch [6/10], Validation Loss: 0.0174\n","Epoch [7/10], Batch [0/255], Generator WGAN Loss: -0.0378, Generator MSE Loss: 0.0022, Discriminator Loss: 0.6217\n","Epoch [7/10], Batch [16/255], Generator WGAN Loss: -0.0691, Generator MSE Loss: 0.0019, Discriminator Loss: 1.1827\n","Epoch [7/10], Batch [32/255], Generator WGAN Loss: -0.0453, Generator MSE Loss: 0.0021, Discriminator Loss: 2.8870\n","Epoch [7/10], Batch [48/255], Generator WGAN Loss: -0.0443, Generator MSE Loss: 0.0023, Discriminator Loss: 1.2549\n","Epoch [7/10], Batch [64/255], Generator WGAN Loss: -0.0096, Generator MSE Loss: 0.0022, Discriminator Loss: 0.1810\n","Epoch [7/10], Batch [80/255], Generator WGAN Loss: -0.0053, Generator MSE Loss: 0.0037, Discriminator Loss: 0.4765\n","Epoch [7/10], Batch [96/255], Generator WGAN Loss: 0.0119, Generator MSE Loss: 0.0013, Discriminator Loss: 0.3058\n","Epoch [7/10], Batch [112/255], Generator WGAN Loss: 0.0015, Generator MSE Loss: 0.0028, Discriminator Loss: 1.3110\n","Epoch [7/10], Batch [128/255], Generator WGAN Loss: -0.0212, Generator MSE Loss: 0.0030, Discriminator Loss: 0.4900\n","Epoch [7/10], Batch [144/255], Generator WGAN Loss: -0.0390, Generator MSE Loss: 0.0098, Discriminator Loss: 1.2975\n","Epoch [7/10], Batch [160/255], Generator WGAN Loss: -0.0137, Generator MSE Loss: 0.0018, Discriminator Loss: 0.1740\n","Epoch [7/10], Batch [176/255], Generator WGAN Loss: -0.0194, Generator MSE Loss: 0.0019, Discriminator Loss: 3.7468\n","Epoch [7/10], Batch [192/255], Generator WGAN Loss: -0.0285, Generator MSE Loss: 0.0016, Discriminator Loss: 2.0398\n","Epoch [7/10], Batch [208/255], Generator WGAN Loss: -0.0176, Generator MSE Loss: 0.0037, Discriminator Loss: 1.4452\n","Epoch [7/10], Batch [224/255], Generator WGAN Loss: -0.0163, Generator MSE Loss: 0.0022, Discriminator Loss: 3.7755\n","Epoch [7/10], Batch [240/255], Generator WGAN Loss: -0.0155, Generator MSE Loss: 0.0018, Discriminator Loss: 2.3493\n","Epoch [7/10], Validation Loss: 0.0175\n","Epoch [8/10], Batch [0/255], Generator WGAN Loss: -0.0120, Generator MSE Loss: 0.0032, Discriminator Loss: 0.7772\n","Epoch [8/10], Batch [16/255], Generator WGAN Loss: -0.0324, Generator MSE Loss: 0.0026, Discriminator Loss: 1.0687\n","Epoch [8/10], Batch [32/255], Generator WGAN Loss: -0.0242, Generator MSE Loss: 0.0022, Discriminator Loss: 1.3316\n","Epoch [8/10], Batch [48/255], Generator WGAN Loss: -0.0698, Generator MSE Loss: 0.0016, Discriminator Loss: 0.9143\n","Epoch [8/10], Batch [64/255], Generator WGAN Loss: -0.0350, Generator MSE Loss: 0.0018, Discriminator Loss: 1.2087\n","Epoch [8/10], Batch [80/255], Generator WGAN Loss: -0.0261, Generator MSE Loss: 0.0015, Discriminator Loss: 0.8232\n","Epoch [8/10], Batch [96/255], Generator WGAN Loss: -0.0395, Generator MSE Loss: 0.0017, Discriminator Loss: 1.6005\n","Epoch [8/10], Batch [112/255], Generator WGAN Loss: -0.0202, Generator MSE Loss: 0.0022, Discriminator Loss: 0.4366\n","Epoch [8/10], Batch [128/255], Generator WGAN Loss: -0.0018, Generator MSE Loss: 0.0028, Discriminator Loss: 2.8291\n","Epoch [8/10], Batch [144/255], Generator WGAN Loss: -0.0161, Generator MSE Loss: 0.0035, Discriminator Loss: 1.3270\n","Epoch [8/10], Batch [160/255], Generator WGAN Loss: -0.0449, Generator MSE Loss: 0.0028, Discriminator Loss: 1.0168\n"]}],"source":["loadModel()\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    generator.train()\n","    discriminator.train()\n","    loss_G = 0\n","    mse_loss_total = 0\n","\n","    for idx, (real_image, grey_image) in enumerate(train_loader):\n","\n","        for _ in range(n_critic):\n","            # Randomly sample a mini batch from real data\n","            subset_indices = torch.randperm(len(train_set))[:mini_batch]\n","\n","            # Create a SubsetRandomSampler using the subset indices\n","            subset_sampler = SubsetRandomSampler(subset_indices)\n","\n","            critic_loader = DataLoader(train_set, batch_size=batch_size, sampler=subset_sampler, num_workers=num_workers)\n","\n","            for i, (real_image_critic, grey_image_critic) in enumerate(critic_loader):\n","                grey_image_critic = grey_image_critic.to(device)\n","                real_image_critic = real_image_critic.to(device)\n","\n","                optimizer_D.zero_grad()\n","\n","                real_output_critic = discriminator(real_image_critic)\n","                fake_image_critic = generator(grey_image_critic)\n","                fake_output_critic = discriminator(fake_image_critic.detach())\n","\n","                # Compute WGAN loss for discriminator with gradient penalty\n","                discriminator_loss = -(torch.mean(real_output_critic) - torch.mean(fake_output_critic))\n","                gradient_penalty = compute_gradient_penalty(discriminator, real_image_critic, fake_image_critic)\n","                discriminator_loss += gradient_penalty * gradient_penalty_lambda\n","\n","\n","                # Update discriminator weights\n","                discriminator_loss.backward()\n","                optimizer_D.step()\n","\n","                # Apply weight clipping  - Needs to try with out it\n","                for p in discriminator.parameters():\n","                    p.data.clamp_(-0.01, 0.01)\n","\n","\n","        grey_image = grey_image.to(device)\n","        real_image = real_image.to(device)\n","\n","        # Train Generator\n","        optimizer_G.zero_grad()\n","        fake_image = generator(grey_image)\n","        fake_output = discriminator(fake_image)\n","\n","        # Compute WGAN loss and MSE Loss for generator\n","        generator_loss_wgan = -torch.mean(fake_output)\n","        generator_loss_mse = criterion(fake_image, real_image)\n","        generator_loss = lambda_wgan * generator_loss_wgan + lambda_mse * generator_loss_mse\n","\n","        # Update generator weights\n","        generator_loss.backward()\n","        optimizer_G.step()\n","\n","\n","        train_losses_discriminator.append(discriminator_loss.item())\n","        train_losses_generator.append(generator_loss.item())\n","        mse_losses.append(generator_loss_mse.item())\n","\n","\n","        if idx % batch_epoch == 0:\n","            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{idx}/{len(train_loader)}], Generator WGAN Loss: {generator_loss_wgan.item():.4f}, Generator MSE Loss: {generator_loss_mse.item():.4f}, Discriminator Loss: {discriminator_loss.item():.4f}\")\n","\n","    # Calculate validation loss\n","    validation_loss, validation_psnr, validation_mae = validate(generator, criterion, validation_loader)\n","\n","\n","    validation_losses.append(validation_loss)\n","    psnr_values.append(validation_psnr)\n","    # ssim_values.append(validation_ssim)\n","    mae_values.append(validation_mae)\n","    print(f\"Epoch [{epoch}/{num_epochs}], Validation Loss: {validation_loss:.4f}\")\n","\n","    if epoch % save_every_epoch == 0:\n","        # Save model checkpoints\n","        torch.save(generator.state_dict(), f\"generator_epoch.pt\")\n","        torch.save(discriminator.state_dict(), f\"discriminator_epoch.pt\")\n","\n","        # Save model checkpoints to Google Drive\n","#         torch.save(generator.state_dict(), '/content/drive/My Drive/generator_epoch.pt')\n","#         torch.save(discriminator.state_dict(), '/content/drive/My Drive/discriminator_epoch.pt')\n","\n","\n","        # Generate random image and its colorized version\n","        real_image, grey_image = random.choice(train_loader.dataset)\n","        grey_image = grey_image.unsqueeze(0).to(device)\n","        colorized_image = generator(grey_image)\n","\n","        # Convert tensors to PIL images\n","        grey_image_pil = transforms.ToPILImage()(grey_image.squeeze().cpu())\n","        colorized_image_pil = transforms.ToPILImage()(colorized_image.squeeze().cpu().detach())\n","        original_image_pil = transforms.ToPILImage()(real_image.cpu())\n","\n","        # Plot and save the images\n","        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n","        axs[0].imshow(grey_image_pil, cmap='gray')\n","        axs[0].set_title(\"Grayscale Image\")\n","        axs[0].axis(\"off\")\n","        axs[1].imshow(colorized_image_pil)\n","        axs[1].set_title(\"Generated Colorized Image\")\n","        axs[1].axis(\"off\")\n","        axs[2].imshow(original_image_pil)\n","        axs[2].set_title(\"Original RGB Image\")\n","        axs[2].axis(\"off\")\n","        plt.savefig(os.path.join('/kaggle/working/', f\"epoch_{epoch + 1}_colorized_image.png\"))\n","#         plt.close()\n","\n","# Plotting\n","plt.figure(figsize=(15, 15))\n","\n","# Training Loss - Discriminator\n","plt.subplot(3, 2, 1)\n","plt.plot(train_losses_discriminator, label='Training Loss - Discriminator')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss - Discriminator')\n","plt.legend()\n","plt.grid(True)\n","\n","# Training Loss - Generator\n","plt.subplot(3, 2, 2)\n","plt.plot(train_losses_generator, label='Training Loss - Generator')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss - Generator')\n","plt.legend()\n","plt.grid(True)\n","\n","# MSE Loss\n","plt.subplot(3, 2, 3)\n","plt.plot(mse_losses, label='MSE Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('MSE Loss')\n","plt.legend()\n","plt.grid(True)\n","\n","# Validation Loss\n","plt.subplot(3, 2, 4)\n","plt.plot(validation_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","\n","# PSNR\n","plt.subplot(3, 2, 5)\n","plt.plot(psnr_values, label='PSNR')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR')\n","plt.title('PSNR')\n","plt.legend()\n","plt.grid(True)\n","\n","# MAE\n","plt.subplot(3, 2, 6)\n","plt.plot(mae_values, label='MAE')\n","plt.xlabel('Epoch')\n","plt.ylabel('MAE')\n","plt.title('MAE')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.savefig('performance_metrics.png')\n","plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator.eval()  # Set the generator to evaluation mode\n","for i, (real_image, gray_image) in enumerate(test_loader):\n","\n","    with torch.no_grad():\n","        # Generate random image and its colorized version\n","        gray_image = gray_image.to(device)\n","        colorized_image = generator(gray_image)  # Remove the batch dimension\n","        colorized_image = colorized_image[0]  # Remove the batch dimension\n","\n","        # Convert tensors to PIL images\n","        gray_image_pil = transforms.ToPILImage()(gray_image[0].cpu())\n","        colorized_image_pil = transforms.ToPILImage()(colorized_image.cpu().detach())\n","        original_image_pil = transforms.ToPILImage()(real_image[0].cpu())\n","\n","        # Plot and save the images\n","        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n","        axs[0].imshow(gray_image_pil, cmap='gray')\n","        axs[0].set_title(\"Grayscale Image\")\n","        axs[0].axis(\"off\")\n","        axs[1].imshow(colorized_image_pil)\n","        axs[1].set_title(\"Generated Colorized Image\")\n","        axs[1].axis(\"off\")\n","        axs[2].imshow(original_image_pil)\n","        axs[2].set_title(\"Original RGB Image\")\n","        axs[2].axis(\"off\")\n","\n","        if i == 5:\n","            break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert lists to DataFrames\n","train_losses_discriminator_df = pd.DataFrame({'train_loss_discriminator': train_losses_discriminator})\n","train_losses_generator_df = pd.DataFrame({'train_loss_generator': train_losses_generator})\n","mse_losses_df = pd.DataFrame({'mse_loss': mse_losses})\n","validation_losses_df = pd.DataFrame({'validation_loss': validation_losses})\n","psnr_values_df = pd.DataFrame({'psnr_value': psnr_values})\n","mae_values_df = pd.DataFrame({'mae_value': mae_values})\n","\n","# Save DataFrames to CSV files\n","train_losses_discriminator_df.to_csv('/kaggle/working/train_losses_discriminator.csv', index=False)\n","train_losses_generator_df.to_csv('/kaggle/working/train_losses_generator.csv', index=False)\n","mse_losses_df.to_csv('/kaggle/working/mse_losses.csv', index=False)\n","validation_losses_df.to_csv('/kaggle/working/validation_losses.csv', index=False)\n","psnr_values_df.to_csv('/kaggle/working/psnr_values.csv', index=False)\n","mae_values_df.to_csv('/kaggle/working/mae_values.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4697763,"sourceId":7981533,"sourceType":"datasetVersion"},{"datasetId":4719012,"sourceId":8010998,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
