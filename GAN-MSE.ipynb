{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-13T06:39:43.829388Z","iopub.status.busy":"2024-04-13T06:39:43.828832Z","iopub.status.idle":"2024-04-13T06:39:50.647771Z","shell.execute_reply":"2024-04-13T06:39:50.646936Z","shell.execute_reply.started":"2024-04-13T06:39:43.829359Z"},"id":"rmyCr3OgROUT","trusted":true},"outputs":[],"source":["from torchvision.datasets import Flowers102\n","import multiprocessing\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from torchvision import transforms\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-13T06:39:50.649821Z","iopub.status.busy":"2024-04-13T06:39:50.649364Z","iopub.status.idle":"2024-04-13T06:39:50.655408Z","shell.execute_reply":"2024-04-13T06:39:50.654410Z","shell.execute_reply.started":"2024-04-13T06:39:50.649794Z"},"id":"76Y_VBtfROUV","outputId":"8c892f4f-4292-45cf-961e-3529c23d2322","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of CPU cores available: 4\n"]}],"source":["num_workers = multiprocessing.cpu_count()\n","print(\"Number of CPU cores available:\", num_workers)\n","batch_size = 4"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-13T06:39:50.656911Z","iopub.status.busy":"2024-04-13T06:39:50.656562Z","iopub.status.idle":"2024-04-13T06:39:59.170809Z","shell.execute_reply":"2024-04-13T06:39:59.169954Z","shell.execute_reply.started":"2024-04-13T06:39:50.656881Z"},"id":"U-UvzU-3ROUX","outputId":"f8d03bd5-ef44-496e-a27b-d6c4afd683a3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to flowers-102/102flowers.tgz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 344862509/344862509 [00:01<00:00, 183246190.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting flowers-102/102flowers.tgz to flowers-102\n","Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to flowers-102/imagelabels.mat\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 502/502 [00:00<00:00, 643109.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to flowers-102/setid.mat\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14989/14989 [00:00<00:00, 12013839.61it/s]\n"]}],"source":["class DataProvider(Dataset):\n","\n","    def __init__(self, sample_dataset, label_dataset):\n","        self.sample_dataset = sample_dataset\n","        self.label_dataset = label_dataset\n","\n","    def __len__(self):\n","        return len(self.sample_dataset)\n","\n","    def __getitem__(self, idx):\n","        sample = self.sample_dataset[idx][0]\n","        label = self.label_dataset[idx][0]\n","        return (sample, label)\n","\n","\n","transform_Grayscale = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor()\n","])\n","\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])\n","\n","# Load sample datasets rgb image\n","train_set_sample = Flowers102(root='.', split='train', download=True, transform=transform)\n","test_set_sample = Flowers102(root='.', split='test', download=True, transform=transform)\n","validation_set_sample = Flowers102(root='.', split='val', download=True, transform=transform)\n","\n","# Load label datasets - grayscale images as labels)\n","train_set_label = Flowers102(root='.', split='train', download=True, transform=transform_Grayscale)\n","test_set_label = Flowers102(root='.', split='test', download=True, transform=transform_Grayscale)\n","validation_set_label = Flowers102(root='.', split='val', download=True, transform=transform_Grayscale)\n","\n","train_set = DataProvider(train_set_sample, train_set_label)\n","test_set = DataProvider(test_set_sample, test_set_label)\n","validation_set = DataProvider(validation_set_sample, validation_set_label)\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-13T06:39:59.173484Z","iopub.status.busy":"2024-04-13T06:39:59.173005Z","iopub.status.idle":"2024-04-13T06:39:59.205683Z","shell.execute_reply":"2024-04-13T06:39:59.204645Z","shell.execute_reply.started":"2024-04-13T06:39:59.173450Z"},"id":"Hj0sx3OjROUZ","outputId":"ce0b9f78-0418-4f7e-b861-a584f21d1d2e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device:', device)"]},{"cell_type":"markdown","metadata":{"id":"RriO1C6qROUa"},"source":["# Generator - UNET"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T06:39:59.207174Z","iopub.status.busy":"2024-04-13T06:39:59.206874Z","iopub.status.idle":"2024-04-13T06:39:59.226537Z","shell.execute_reply":"2024-04-13T06:39:59.225652Z","shell.execute_reply.started":"2024-04-13T06:39:59.207148Z"},"id":"Z9eFuvj_ROUd","trusted":true},"outputs":[],"source":["class VGGBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout_rate=0.0):\n","        super(VGGBlock, self).__init__()\n","        layers = [\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        ]\n","       \n","        if dropout_rate > 0.0:\n","            layers.append(nn.Dropout(dropout_rate))\n","        \n","        self.conv = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNetGenerator(nn.Module):\n","    def __init__(self):\n","        super(UNetGenerator, self).__init__()\n","        \n","        # Pooling and upsampling\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        \n","        # Encoder: Downsampling path\n","        self.encoder_block1 = VGGBlock(1, 64)\n","        self.encoder_block2 = VGGBlock(64, 128)\n","        self.encoder_block3 = VGGBlock(128, 256)\n","        self.encoder_block4 = VGGBlock(256, 512)\n","        self.encoder_block5 = VGGBlock(512, 512)\n","        self.encoder_block6 = VGGBlock(512, 1024)\n","        \n","        # Decoder: Upsampling path\n","        self.decoder_block5 = VGGBlock(512 + 1024, 512)\n","        self.decoder_block4 = VGGBlock(512 + 512, 256)\n","        self.decoder_block3 = VGGBlock(256 + 256, 256)\n","        self.decoder_block2 = VGGBlock(128 + 256, 128)\n","        self.decoder_block1 = VGGBlock(128 + 64, 64)\n","        \n","        # Final convolution\n","        self.conv_last = nn.Conv2d(64, 3, kernel_size=1)\n","        \n","    def forward(self, x):\n","        # Downsample\n","        conv1 = self.encoder_block1(x)\n","        conv2 = self.encoder_block2(self.maxpool(conv1))\n","        conv3 = self.encoder_block3(self.maxpool(conv2))\n","        conv4 = self.encoder_block4(self.maxpool(conv3))\n","        conv5 = self.encoder_block5(self.maxpool(conv4))\n","        x = self.encoder_block6(self.maxpool(conv5))\n","\n","        # Upsample and concatenate\n","        x = torch.cat([self.upsample(x), conv5], dim=1)\n","        x = torch.cat([self.upsample(self.decoder_block5(x)), conv4], dim=1)       \n","        x = torch.cat([self.upsample(self.decoder_block4(x)), conv3], dim=1)     \n","        x = torch.cat([self.upsample(self.decoder_block3(x)), conv2], dim=1)            \n","        x = torch.cat([self.upsample(self.decoder_block2(x)), conv1], dim=1)   \n","        \n","        # Final convolution\n","        out = self.conv_last(self.decoder_block1(x))\n","        \n","        return out"]},{"cell_type":"markdown","metadata":{"id":"wibohoHIROUe"},"source":["# Discriminator - CNN"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T06:39:59.228244Z","iopub.status.busy":"2024-04-13T06:39:59.227884Z","iopub.status.idle":"2024-04-13T06:39:59.242644Z","shell.execute_reply":"2024-04-13T06:39:59.241575Z","shell.execute_reply.started":"2024-04-13T06:39:59.228213Z"},"id":"q9Zx8-q7ROUf","trusted":true},"outputs":[],"source":["class VGG_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout_rate=0.0):\n","        super(VGG_block, self).__init__()\n","        layers = [\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.InstanceNorm2d(out_channels, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.InstanceNorm2d(out_channels, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        ]\n","        \n","        if dropout_rate > 0.0:\n","            layers.append(nn.Dropout(dropout_rate))\n","        \n","        layers.append(nn.MaxPool2d(2))\n","        \n","        self.block = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.block(x)\n","    \n","    \n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","                \n","        self.layer1 = VGG_block(3, 64)  \n","        self.layer2 = VGG_block(64, 128)\n","        self.layer3 = VGG_block(128, 256)\n","        self.layer4 = VGG_block(256, 512)\n","        self.layer5 = VGG_block(512, 1024)\n","        self.layer6 = VGG_block(1024, 1024)\n","        \n","        # Final convolutional layer\n","        self.final_conv = nn.Sequential(\n","            nn.Conv2d(1024, 1, kernel_size=3, stride=1, padding=1, bias=False)\n","        )\n","\n","    def forward(self, img):\n","        x1 = self.layer1(img)\n","        x2 = self.layer2(x1)\n","        x3 = self.layer3(x2)\n","        x4 = self.layer4(x3)\n","        x5 = self.layer5(x4)\n","        x6 = self.layer6(x5)\n","        output = self.final_conv(x6)\n","        return torch.sigmoid(output)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvdMK8GMROUh","trusted":true},"outputs":[],"source":["# Initialize the generator and discriminator\n","generator = UNetGenerator()  # Input is grayscale, output is color\n","discriminator = Discriminator()\n","\n","optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","adversarial_loss = nn.BCEWithLogitsLoss()\n","mse_loss = nn.MSELoss()\n","\n","generator = generator.to(device)\n","discriminator = discriminator.to(device)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T06:40:00.284490Z","iopub.status.busy":"2024-04-13T06:40:00.284212Z","iopub.status.idle":"2024-04-13T06:40:00.297425Z","shell.execute_reply":"2024-04-13T06:40:00.296453Z","shell.execute_reply.started":"2024-04-13T06:40:00.284462Z"},"id":"KfJiv7yhROUj","trusted":true},"outputs":[],"source":["def psnr(image_true, image_pred):\n","    mse = F.mse_loss(image_pred, image_true)\n","    max_pixel = 1.0\n","    return 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","\n","def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n","    mean1 = img1.mean([2, 3])\n","    mean2 = img2.mean([2, 3])\n","    std1 = img1.std([2, 3])\n","    std2 = img2.std([2, 3])\n","    std12 = (img1 * img2).mean([2, 3]) - mean1 * mean2\n","    \n","    ssim_n = (2 * mean1 * mean2 + C1) * (2 * std12 + C2)\n","    ssim_d = (mean1**2 + mean2**2 + C1) * (std1**2 + std2**2 + C2)\n","    \n","    return ssim_n / ssim_d\n","\n","def validate(generator, criterion, validation_loader):\n","    generator.eval()  # Set the generator to evaluation mode\n","    total_loss = 0\n","    total_psnr = 0\n","    total_mae = 0\n","    total_ssim = 0\n","\n","    with torch.no_grad():\n","        for real_image, grey_image in validation_loader:\n","            grey_image = grey_image.to(device)\n","            real_image = real_image.to(device)\n","            # Generate fake images\n","            fake_image = generator(grey_image)\n","\n","            # Compute MSE loss\n","            loss = criterion(fake_image, real_image)\n","            # Accumulate total loss\n","            total_loss += loss.item()\n","\n","            # Compute PSNR\n","            psnr_value = psnr(real_image, fake_image)\n","            total_psnr += psnr_value.item()\n","\n","            # Compute SSIM\n","            ssim_value = ssim(real_image, fake_image)\n","            total_ssim += ssim_value.mean().item()\n","            \n","            # Compute MAE\n","            mae_value = F.l1_loss(fake_image, real_image)\n","            total_mae += mae_value.item()\n","\n","    # Calculate average validation loss and other metrics\n","    avg_loss = total_loss / len(validation_loader)\n","    avg_psnr = total_psnr / len(validation_loader)\n","    avg_ssim = total_ssim / len(validation_loader)\n","    avg_mae = total_mae / len(validation_loader)\n","\n","    return avg_loss, avg_psnr, avg_ssim, avg_mae\n","\n","\n","def loadModel():\n","    generator.load_state_dict(torch.load('/kaggle/working/MSE_generator_epoch.pt'))\n","    discriminator.load_state_dict(torch.load('/kaggle/working/MSE_discriminator_epoch.pt'))\n","    print(\"Models found in both paths.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T06:40:00.298895Z","iopub.status.busy":"2024-04-13T06:40:00.298583Z","iopub.status.idle":"2024-04-13T06:40:00.311049Z","shell.execute_reply":"2024-04-13T06:40:00.310172Z","shell.execute_reply.started":"2024-04-13T06:40:00.298868Z"},"id":"TBPSXPPbROUm","trusted":true},"outputs":[],"source":["# Hyperparameters\n","batch_epoch = 16\n","lambda_adv = 0.01\n","lambda_mse = 0.99\n","\n","# Training loop\n","num_epochs = 350\n","save_every_epoch = 30\n","\n","# Lists to store losses\n","train_losses_discriminator = []\n","train_losses_generator = []\n","mse_losses = []\n","validation_losses = []\n","psnr_values = []\n","mae_values = []\n","ssim_values = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.idle":"2024-04-13T15:51:22.820442Z","shell.execute_reply":"2024-04-13T15:51:22.819368Z","shell.execute_reply.started":"2024-04-13T06:40:00.314777Z"},"id":"XX7atmu8ROUm","outputId":"4959e699-f45b-4db8-8830-88ad944db1e1","trusted":true},"outputs":[],"source":["total_discriminator_loss = 0.0\n","total_generator_loss = 0.0\n","total_mse_loss = 0.0\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    generator.train()\n","    discriminator.train()\n","\n","    for idx, (real_image, gray_image) in enumerate(train_loader):\n","        batch_size = gray_image.size(0)\n","        \n","        gray_image = gray_image.to(device)\n","        real_image = real_image.to(device)\n","\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","        optimizer_D.zero_grad()\n","        \n","        # Train discriminator with real images\n","        real_predictions = discriminator(real_image)\n","        real_labels = torch.ones_like(real_predictions).to(device) # Real labels\n","        real_loss = adversarial_loss(real_predictions, real_labels)\n","\n","        # Train discriminator with fake images\n","        fake_color_image = generator(gray_image).detach()\n","        fake_predictions = discriminator(fake_color_image) \n","        fake_labels = torch.zeros_like(fake_predictions).to(device)  # Label for fake images\n","        fake_loss = adversarial_loss(fake_predictions, fake_labels)\n","\n","        # Total discriminator loss\n","        discriminator_loss = real_loss + fake_loss\n","\n","        # Update discriminator weights\n","        discriminator_loss.backward()\n","        optimizer_D.step()\n","\n","        # -----------------\n","        #  Train Generator\n","        # -----------------\n","    \n","        optimizer_G.zero_grad()\n","        fake_image = generator(gray_image)\n","        fake_predictions = discriminator(fake_image)\n","        \n","        \n","        real_labels = torch.ones_like(fake_predictions).to(device) # Label for real images\n","        generator_loss_adv = adversarial_loss(fake_predictions, real_labels)\n","        \n","       \n","        # Compute MSE loss between generated color images and ground truth\n","        generator_loss_mse = mse_loss(fake_image, real_image)\n","        \n","         # Combine adversarial loss and MSE loss\n","        generator_loss =  lambda_adv * generator_loss_adv + lambda_mse * generator_loss_mse\n","\n","\n","        # Update generator weights\n","        generator_loss.backward()\n","        optimizer_G.step()\n","\n","        train_losses_discriminator.append(discriminator_loss.item())\n","        train_losses_generator.append(generator_loss.item())\n","        mse_losses.append(generator_loss_mse.item())\n","\n","\n","        if idx % batch_epoch == 0:\n","            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{idx}/{len(train_loader)}], Generator GAN Loss: {generator_loss.item():.4f}, Generator MSE Loss: {generator_loss_mse.item():.4f}, Discriminator Loss: {discriminator_loss.item():.4f}\")\n","\n","    # Calculate validation loss\n","    validation_loss, validation_psnr, validation_ssim, validation_mae = validate(generator, mse_loss, validation_loader)\n","\n","    validation_losses.append(validation_loss)\n","    psnr_values.append(validation_psnr)\n","    mae_values.append(validation_mae)\n","    ssim_values.append(validation_ssim)\n","    print(f\"Epoch [{epoch}/{num_epochs}], Validation Loss: {validation_loss:.4f}\")\n","\n","    if epoch % save_every_epoch == 0:\n","        # Save model checkpoints\n","        torch.save(generator.state_dict(), f\"generator_epoch.pt\")\n","        torch.save(discriminator.state_dict(), f\"discriminator_epoch.pt\")\n","\n","        # Generate random image and its colorized version\n","        real_image, grey_image = random.choice(train_loader.dataset)\n","        grey_image = grey_image.unsqueeze(0).to(device)\n","        colorized_image = generator(grey_image)\n","\n","        # Convert tensors to PIL images\n","        grey_image_pil = transforms.ToPILImage()(grey_image.squeeze().cpu())\n","        colorized_image_pil = transforms.ToPILImage()(colorized_image.squeeze().cpu().detach())\n","        original_image_pil = transforms.ToPILImage()(real_image.cpu())\n","\n","        # Plot and save the images\n","        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n","        axs[0].imshow(grey_image_pil, cmap='gray')\n","        axs[0].set_title(\"Grayscale Image\")\n","        axs[0].axis(\"off\")\n","        axs[1].imshow(colorized_image_pil)\n","        axs[1].set_title(\"Generated Colorized Image\")\n","        axs[1].axis(\"off\")\n","        axs[2].imshow(original_image_pil)\n","        axs[2].set_title(\"Original RGB Image\")\n","        axs[2].axis(\"off\")\n","        plt.savefig(os.path.join('/kaggle/working/', f\"epoch_{epoch + 1}_colorized_image.png\"))\n","\n","\n","\n","# Plotting\n","plt.figure(figsize=(15, 15))\n","\n","# Training Loss - Discriminator\n","plt.subplot(4, 2, 1)\n","plt.plot(train_losses_discriminator, label='Training Loss - Discriminator')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss - Discriminator')\n","plt.legend()\n","plt.grid(True)\n","\n","# Training Loss - Generator\n","plt.subplot(4, 2, 2)\n","plt.plot(train_losses_generator, label='Training Loss - Generator')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss - Generator')\n","plt.legend()\n","plt.grid(True)\n","\n","# MSE Loss\n","plt.subplot(4, 2, 3)\n","plt.plot(mse_losses, label='MSE Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('MSE Loss')\n","plt.legend()\n","plt.grid(True)\n","\n","# Validation Loss\n","plt.subplot(4, 2, 4)\n","plt.plot(validation_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","\n","# PSNR\n","plt.subplot(4, 2, 5)\n","plt.plot(psnr_values, label='PSNR')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR')\n","plt.title('PSNR')\n","plt.legend()\n","plt.grid(True)\n","\n","# MAE\n","plt.subplot(4, 2, 6)\n","plt.plot(mae_values, label='MAE')\n","plt.xlabel('Epoch')\n","plt.ylabel('MAE')\n","plt.title('MAE')\n","plt.legend()\n","plt.grid(True)\n","\n","#SSIM\n","plt.subplot(4, 2, 7)\n","plt.plot(ssim_values, label='SSIM')\n","plt.xlabel('Epoch')\n","plt.ylabel('SSIM')\n","plt.title('SSIM')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.savefig('performance_metrics.png')\n","plt.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T17:11:26.319370Z","iopub.status.busy":"2024-04-13T17:11:26.318975Z","iopub.status.idle":"2024-04-13T17:11:27.064100Z","shell.execute_reply":"2024-04-13T17:11:27.063011Z","shell.execute_reply.started":"2024-04-13T17:11:26.319340Z"},"trusted":true},"outputs":[],"source":["torch.save(generator.state_dict(), f\"generator_epoch.pt\")\n","torch.save(discriminator.state_dict(), f\"discriminator_epoch.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T17:11:30.428906Z","iopub.status.busy":"2024-04-13T17:11:30.428535Z","iopub.status.idle":"2024-04-13T17:11:51.044153Z","shell.execute_reply":"2024-04-13T17:11:51.043158Z","shell.execute_reply.started":"2024-04-13T17:11:30.428879Z"},"trusted":true},"outputs":[],"source":["generator.eval()  # Set the generator to evaluation mode\n","for i, (real_image, gray_image) in enumerate(test_loader):\n","\n","    with torch.no_grad():\n","        # Generate random image and its colorized version\n","        gray_image = gray_image.to(device)\n","        colorized_image = generator(gray_image)  \n","        colorized_image = colorized_image[0]  \n","\n","        # Convert tensors to PIL images\n","        gray_image_pil = transforms.ToPILImage()(gray_image[0].cpu())\n","        colorized_image_pil = transforms.ToPILImage()(colorized_image.cpu().detach())\n","        original_image_pil = transforms.ToPILImage()(real_image[0].cpu())\n","\n","        # Plot and save the images\n","        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n","        axs[0].imshow(gray_image_pil, cmap='gray')\n","        axs[0].set_title(\"Grayscale Image\")\n","        axs[0].axis(\"off\")\n","        axs[1].imshow(colorized_image_pil)\n","        axs[1].set_title(\"Generated Colorized Image\")\n","        axs[1].axis(\"off\")\n","        axs[2].imshow(original_image_pil)\n","        axs[2].set_title(\"Original RGB Image\")\n","        axs[2].axis(\"off\")\n","\n","        if i == 30:\n","            break"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
